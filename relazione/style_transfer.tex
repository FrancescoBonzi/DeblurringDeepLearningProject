\begin{document}
As regard the second technique, we tried to investigate another approach, based on the neural style transfer \cite{G&E&B}. In the following, it is explained how this technique works and then how we used it to solve the deblurring problem for the CIFAR10 dataset.

Neural style transfer is an optimization technique used to take two images, a content image and a style reference image, and blend them together so the output image looks like the content image, but “painted” in the style of the style reference image.
This is implemented by optimizing the output image to match the content statistics of the content image and the style statistics of the style reference image. These statistics are extracted from the images using a convolutional network.

In this case, the VGG19 network architecture is used, a pretrained image classification network. These intermediate layers are necessary to define the representation of content and style from the images.

At a high level, in order for a network to perform image classification, it must understand the image. This requires taking the raw image as input pixels and building an internal representation that converts the raw image pixels into a complex understanding of the features present within the image. This is also a reason why convolutional neural networks are able to generalize well: they’re able to capture the invariances and defining features within classes (e.g. cats vs. dogs) that are agnostic to background noise and other nuisances. Thus, somewhere between where the raw image is fed into the model and the output classification label, the model serves as a complex feature extractor. By accessing intermediate layers of the model, we are able to describe the content and style of input images.
\end{document}
